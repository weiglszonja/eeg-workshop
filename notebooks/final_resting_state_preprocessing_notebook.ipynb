{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing pipeline\n",
    "\n",
    "## Outline\n",
    "\n",
    "<img src=\"static/preprocessing_pipeline_diagram.svg\">\n",
    "\n",
    "1. __Temporal filtering__\n",
    "\n",
    "High-frequency artefacts and slow drifts are removed with a zero-phase bandpass filter \n",
    "using mne-Python [1]. \n",
    "\n",
    "2. __Segmenting the data__\n",
    "\n",
    "Epochs are non-overlapping data segments created from the continuous data with a \n",
    "given duration.\n",
    "Epochs can be created from (1) events; there is a custom method that created epochs \n",
    "based on annotations in the raw data, (2) without events, data segments are created \n",
    "from the beginning of the raw data. \n",
    "\n",
    "3. __Outlier data rejection__  \n",
    "\n",
    "- _Preliminar rejection_\n",
    "\n",
    "Epochs are rejected based on a global threshold on the z-score (> 3) of the epoch \n",
    "variance and amplitude range.\n",
    "\n",
    "- _ICA decomposition_  \n",
    "\n",
    "The default method is the infomax algorithm, however it can be changed in the \n",
    "configuration file along with the number of components and the decimation parameter. \n",
    "Components containing blink artefacts are automatically marked with mne-Python.\n",
    "The ICA sourced can be visualized and interactively selected and rejected based on \n",
    "their topographies, time-courses or frequency spectra.\n",
    "\n",
    "- _Autoreject_  \n",
    "\n",
    "Autoreject [2, 3] uses unsupervised learning to estimate the rejection threshold for \n",
    "the epochs. In order to reduce computation time that increases with the number of \n",
    "segments and channels, autoreject can be fitted on a representative subset of epochs \n",
    "(25% of total epochs). Once the parameters are learned, the solution can be applied to \n",
    "any data that contains channels that were used during fit.\n",
    "\n",
    "4. __Outlier channel interpolation__\n",
    "\n",
    "The Random Sample Consensus (RANSAC) algorithm [4] selects a random subsample of good \n",
    "channels to make predictions of each channel in small non-overlapping 4 seconds long \n",
    "time windows. It uses a method of spherical splines (Perrin et al., 1989) to \n",
    "interpolate the bad sensors.\n",
    "\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower);    \n",
    "\n",
    "switch to ```%matplotlib inline``` for faster but static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import pandas as pd\n",
    "\n",
    "from meeg_tools.preprocessing import *\n",
    "from meeg_tools.utils.epochs import create_epochs_from_intervals\n",
    "from meeg_tools.utils.raw import read_raw_measurement, filter_raw, concat_raws_with_suffix\n",
    "from meeg_tools.utils.log import update_log\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data\n",
    "\n",
    "See [this](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html) documentation for help with supported file formats.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "base_path = '/Users/weian/Downloads/Raw_data/'\n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected file (when the data was recorded in one piece i.e. there is only one recording in the folder)\n",
    "raw = read_raw_measurement(raw_file_path=fc.selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate raw data\n",
    "\n",
    "We can use this function when there was an issue with the recording and there are multiple EEG recordings for one measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we choose a folder and NOT a file name as before\n",
    "#raws_folder_path = '/Users/weian/Downloads/EEG-3/'\n",
    "\n",
    "# with the suffix argument we specify what kind of files to look for\n",
    "#raw = concat_raws_with_suffix(path_to_raw_files=raws_folder_path, suffix='.vhdr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw.copy().crop(tmin=600, tmax=1200).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select condition\n",
    "\n",
    "The current logic for saving the preprocessed files is to create subfolders inside `base_path`,\n",
    "with the name \"preprocessed\" and the name of the condition (e.g. \"epochs_asrt\", \"epochs_rs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'epochs_rs'\n",
    "\n",
    "\n",
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "epochs_path = os.path.join(base_path, folder_name, condition)\n",
    "\n",
    "\n",
    "# Create path to epoch files\n",
    "if not os.path.exists(epochs_path):\n",
    "    os.makedirs(epochs_path)\n",
    "    \n",
    "print(epochs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal filtering\n",
    "\n",
    "We apply a bandpass filter on the continuous data using the `filter_raw` function.\n",
    "\n",
    "The default parameters can be checked with `settings['bandpass_filter']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['bandpass_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_bandpass = filter_raw(raw=raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epochs\n",
    "### B. Create epochs with a fixed duration\n",
    "- not relative to stimulus onset\n",
    "\n",
    "For this we are using the `settings['epochs']['duration']` setting.\n",
    "\n",
    "B. 1. Epochs are created based on a stimulus interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['epochs']['duration'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = create_epochs_from_intervals(raw_bandpass, [(83, 84), (87, 88)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "\n",
    "\n",
    "### 1.1. Preliminary epoch rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_faster = prepare_epochs_for_ica(epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run ICA\n",
    "\n",
    "\n",
    "When visualizing the components, it is recommended to subset the data (see below).\n",
    "\n",
    "\n",
    "Picard can be used to solve the same problems as FastICA, Infomax, and extended Infomax, but typically converges faster than either of those methods. To make use of Picard’s speed while still obtaining the same solution as with other algorithms, you need to specify method='picard' and fit_params as a dictionary with the following combination of keys:\n",
    "\n",
    "dict(ortho=False, extended=False) for Infomax  \n",
    "\n",
    "dict(ortho=False, extended=True) for extended Infomax  \n",
    "\n",
    "dict(ortho=True, extended=True) for FastICA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"ica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = run_ica(epochs_faster, fit_params=dict(ortho=False, extended=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize components on epochs\n",
    "# Subset epochs to reduce execution time (e.g. take epochs from every 7th event)\n",
    "#subset = list(epochs.event_id.keys())[::7]\n",
    "# Exclude components by selecting them, right click on component name to visualize source:\n",
    "ica.plot_sources(epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot component topographies\n",
    "ica.plot_components()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "epochs_ica = apply_ica(epochs_faster, ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs_ica.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save cleaned epochs (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(epochs_path, f'{epochs_ica.info[\"temp\"]}-epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.save(os.path.join(epochs_path, f'{epochs_ica.info[\"temp\"]}-epo.fif.gz'),\n",
    "                overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create a log file \n",
    "\n",
    "We can create a log file for the preprocessed data and store metadata\n",
    "that could be useful to remember. You can add more columns to this, or \n",
    "remove the ones that are not needed. For documentation purporses, it is \n",
    "recommended to store the number of rejected and total epochs, the number of\n",
    "ICA components that were rejected, the number of interpolated electrodes etc.\n",
    "You can also add a column with \"notes\" to add custom descriptions about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"log\"] = \"Your name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log(epochs_path, epochs_ica, notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_log = run_autoreject(epochs_ica, subset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_log.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can decide how strict should be the epoch rejection.\n",
    "# You can drop only those that were marked as bad epochs, or a more \n",
    "# strict rejection threshold can be if you drop epochs where more than\n",
    "# 15% of the channels were marked as noisy.\n",
    "\n",
    "# You can plot the epochs with Autoreject, where bad epochs are marked with\n",
    "# red colors. \n",
    "\n",
    "#reject_log.plot_epochs(epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_autoreject = apply_autoreject(epochs=epochs_ica, reject_log=reject_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(epochs_path, f'{epochs_autoreject.info[\"temp\"]}-epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_autoreject.save(os.path.join(epochs_path, f'{epochs_autoreject.info[\"temp\"]}-epo.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update log\n",
    "notes = ''\n",
    "\n",
    "update_log(epochs_path, epochs_autoreject, notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find and interpolate bad channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = get_noisy_channels(epochs=epochs_autoreject, with_ransac=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bads.extend(['T7', 'CPz'])\n",
    "\n",
    "# .append() for string e.g. 'F7'\n",
    "# .extend() for list ['F7', 'F8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac = interpolate_bad_channels(epochs=epochs_autoreject, bads=bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs_ransac.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final visual inspection\n",
    "\n",
    "Mark epochs that should be dropped,  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use indexing to plot fewer epochs (faster) e.g. [::7] shows only every 7th epoch\n",
    "epochs_ransac.plot(n_epochs=10,\n",
    "                       n_channels=32,\n",
    "                # group_by='position',\n",
    "                       scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Set average reference\n",
    "\n",
    "To set a “virtual reference” that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.set_eeg_reference('average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save cleaned epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(epochs_path, f'{epochs_ransac.info[\"temp\"]}-epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.save(os.path.join(epochs_path, f'{epochs_ransac.info[\"temp\"]}-epo.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log(epochs_path, epochs_ransac, '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
