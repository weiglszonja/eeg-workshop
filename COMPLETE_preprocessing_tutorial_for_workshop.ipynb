{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing pipeline tutorial\n",
    "\n",
    "## Outline\n",
    "\n",
    "<img src=\"static/preprocessing_pipeline_diagram.svg\">\n",
    "\n",
    "1. __Temporal filtering__\n",
    "\n",
    "High-frequency artefacts and slow drifts are removed with a zero-phase bandpass filter \n",
    "using mne-Python [1]. \n",
    "\n",
    "2. __Segmenting the data__\n",
    "\n",
    "Epochs are non-overlapping data segments created from the continuous data with a \n",
    "given duration.\n",
    "Epochs can be created from (1) events; there is a custom method that created epochs \n",
    "based on annotations in the raw data, (2) without events, data segments are created \n",
    "from the beginning of the raw data. \n",
    "\n",
    "3. __Outlier data rejection__  \n",
    "\n",
    "- _Preliminar rejection_\n",
    "\n",
    "Epochs are rejected based on a global threshold on the z-score (> 3) of the epoch \n",
    "variance and amplitude range.\n",
    "\n",
    "- _ICA decomposition_  \n",
    "\n",
    "The default method is the infomax algorithm, however it can be changed in the \n",
    "configuration file along with the number of components and the decimation parameter. \n",
    "Components containing blink artefacts are automatically marked with mne-Python.\n",
    "The ICA sourced can be visualized and interactively selected and rejected based on \n",
    "their topographies, time-courses or frequency spectra.\n",
    "\n",
    "- _Autoreject_  \n",
    "\n",
    "Autoreject [2, 3] uses unsupervised learning to estimate the rejection threshold for \n",
    "the epochs. In order to reduce computation time that increases with the number of \n",
    "segments and channels, autoreject can be fitted on a representative subset of epochs \n",
    "(25% of total epochs). Once the parameters are learned, the solution can be applied to \n",
    "any data that contains channels that were used during fit.\n",
    "\n",
    "4. __Outlier channel interpolation__\n",
    "\n",
    "The Random Sample Consensus (RANSAC) algorithm [4] selects a random subsample of good \n",
    "channels to make predictions of each channel in small non-overlapping 4 seconds long \n",
    "time windows. It uses a method of spherical splines (Perrin et al., 1989) to \n",
    "interpolate the bad sensors.\n",
    "\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower);    \n",
    "\n",
    "switch to ```%matplotlib inline``` for faster but static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import pandas as pd\n",
    "\n",
    "from meeg_tools.preprocessing import *\n",
    "from meeg_tools.utils.epochs import create_epochs_from_events, create_metadata\n",
    "from meeg_tools.utils.raw import read_raw_measurement, filter_raw\n",
    "from meeg_tools.utils.log import update_log\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "\n",
    "\n",
    "See [this](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html) documentation for help with supported file formats.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bde4b16a98d4048bc1b72e8d8516c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data', filename=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "base_path = '/Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data'\n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data/61_E/Day1/EEG/61_E_Day1.vhdr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data/61_E/Day1/EEG/61_E_Day1.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    }
   ],
   "source": [
    "# Load selected file\n",
    "raw = read_raw_measurement(raw_file_path=fc.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, Pz, P3, ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 64 items (64 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: 2021-02-08 14:08:06 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      " temp: 61_E_Day1\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw.copy().crop(tmin=600, tmax=1200).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select condition\n",
    "\n",
    "The current logic for saving the preprocessed files is to create subfolders inside `base_path`,\n",
    "with the name \"preprocessed\" and the name of the condition (e.g. \"epochs_asrt\", \"epochs_rs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data/preprocessed/epochs_asrt\n"
     ]
    }
   ],
   "source": [
    "condition = 'epochs_asrt'\n",
    "\n",
    "\n",
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "epochs_path = os.path.join(base_path, folder_name, condition)\n",
    "\n",
    "\n",
    "# Create path to epoch files\n",
    "if not os.path.exists(epochs_path):\n",
    "    os.makedirs(epochs_path)\n",
    "    \n",
    "print(epochs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal filtering\n",
    "\n",
    "We apply a bandpass filter on the continuous data using the `filter_raw` function.\n",
    "\n",
    "The default parameters can be checked with `settings['bandpass_filter']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'low_freq': 0.5, 'high_freq': 45}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings[\"bandpass_filter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 3250369  =      0.000 ...  6500.738 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done  64 out of  64 | elapsed:   16.8s finished\n"
     ]
    }
   ],
   "source": [
    "raw_bandpass = filter_raw(raw=raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epochs\n",
    "\n",
    "### Create epochs for event-related analysis\n",
    "\n",
    "We create epochs from __selected__ events (stimuli) in the data.\n",
    "\n",
    "Epochs are created with respect to the stimulus onset defined by `start_time` and \n",
    "`end_time` within `settings['epochs']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': 0.0, 'end_time': 1.0, 'duration': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['epochs']['start_time'] = -0.250\n",
    "settings['epochs']['end_time'] = 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 149 150 151 152 211 212 213 214\n",
      " 215 216]\n"
     ]
    }
   ],
   "source": [
    "events_ids = np.concatenate([np.arange(10, 53, 1), \n",
    "                             np.arange(10, 53, 1) + 100,\n",
    "                            [211, 212, 213, 214, 215, 216]]) # boundaries of epochs\n",
    "\n",
    "print(events_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  5', 'Stimulus/S 10', 'Stimulus/S 11', 'Stimulus/S 12', 'Stimulus/S 14', 'Stimulus/S 15', 'Stimulus/S 16', 'Stimulus/S 17', 'Stimulus/S 18', 'Stimulus/S 19', 'Stimulus/S 20', 'Stimulus/S 21', 'Stimulus/S 22', 'Stimulus/S 24', 'Stimulus/S 25', 'Stimulus/S 26', 'Stimulus/S 27', 'Stimulus/S 28', 'Stimulus/S 29', 'Stimulus/S 30', 'Stimulus/S 31', 'Stimulus/S 32', 'Stimulus/S 34', 'Stimulus/S 35', 'Stimulus/S 36', 'Stimulus/S 37', 'Stimulus/S 38', 'Stimulus/S 39', 'Stimulus/S 40', 'Stimulus/S 41', 'Stimulus/S 42', 'Stimulus/S 43', 'Stimulus/S 44', 'Stimulus/S 45', 'Stimulus/S 46', 'Stimulus/S 47', 'Stimulus/S 48', 'Stimulus/S 49', 'Stimulus/S 51', 'Stimulus/S 52', 'Stimulus/S 61', 'Stimulus/S 62', 'Stimulus/S 63', 'Stimulus/S 64', 'Stimulus/S 65', 'Stimulus/S 66', 'Stimulus/S 67', 'Stimulus/S 68', 'Stimulus/S 69', 'Stimulus/S 70', 'Stimulus/S 71', 'Stimulus/S 72', 'Stimulus/S 75', 'Stimulus/S 76', 'Stimulus/S 77', 'Stimulus/S 78', 'Stimulus/S 80', 'Stimulus/S 81', 'Stimulus/S 83', 'Stimulus/S 84', 'Stimulus/S 85', 'Stimulus/S 87', 'Stimulus/S 88', 'Stimulus/S 89', 'Stimulus/S 91', 'Stimulus/S 92', 'Stimulus/S 93', 'Stimulus/S 94', 'Stimulus/S 95', 'Stimulus/S 96', 'Stimulus/S 97', 'Stimulus/S 98', 'Stimulus/S 99', 'Stimulus/S100', 'Stimulus/S103', 'Stimulus/S104', 'Stimulus/S106', 'Stimulus/S160', 'Stimulus/S161', 'Stimulus/S162', 'Stimulus/S163', 'Stimulus/S164', 'Stimulus/S165', 'Stimulus/S200', 'Stimulus/S201', 'Stimulus/S202', 'Stimulus/S203', 'Stimulus/S205', 'Stimulus/S210', 'Stimulus/S211', 'Stimulus/S212', 'Stimulus/S213', 'Stimulus/S214', 'Stimulus/S215']\n",
      "Creating epochs from selected events ...\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "6679 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs = create_epochs_from_events(raw=raw_bandpass, event_ids=events_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs['10'].average().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata for epochs (optional)\n",
    "\n",
    "- adding metadata makes it easier to select epochs of different types\n",
    "- custom triggers are selected from the raw instance\n",
    "\n",
    "- metadata can be added or replaced later (e.g. after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these indices for these epoch boundary events: \n",
      "211\t1345\n",
      "212\t2687\n",
      "213\t4018\n",
      "214\t5351\n",
      "215\t6678\n",
      "Adding metadata with 8 columns\n"
     ]
    }
   ],
   "source": [
    "metadata = create_metadata(epochs=epochs)\n",
    "\n",
    "# We have to assign it to the epochs instance to take effect\n",
    "epochs.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs[\"triplet == 'L' | triplet == 'H'\"].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselecting epochs \n",
    "# Here we could also include thrills, repetitions, or practice stimuli.\n",
    "# ICA should not run on duplicate data (epochs should not be overlapping!)\n",
    "\n",
    "epochs = epochs[\"triplet == 'L' | triplet == 'H'\"]\n",
    "epochs = epochs[\"answer == 'correct'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs.metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[::7].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "\n",
    "\n",
    "### 1.1. Preliminary epoch rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preliminary epoch rejection: \n",
      "Loading data for 1599 events and 726 original time points ...\n",
      "0 bad epochs dropped\n",
      "Bad epochs by amplitude\n",
      "\t[   9   27   32   49   50  110  130  137  139  191  268  269  295  319\n",
      "  498  753  754  761  815  905  906 1166 1221 1344 1345 1417 1481 1522]\n",
      "Bad epochs by deviation\n",
      "\t[  10   12   27   28   32   33   47   49   50   61   62  110  130  138\n",
      "  139  163  182  191  192  267  268  269  270  294  295  296  310  319\n",
      "  320  325  335  336  337  408  497  498  519  523  525  561  562  578\n",
      "  600  622  623  752  753  760  761  814  905  906  926  927  968  970\n",
      " 1013 1014 1158 1166 1168 1220 1344 1345 1346 1358 1418 1420 1429 1430\n",
      " 1472 1551]\n",
      "Bad epochs by variance\n",
      "\t[   9   24   27   32   49   50   66  110  130  137  139  191  235  268\n",
      "  269  295  319  327  335  408  411  498  753  754  761  815  905  906\n",
      "  926 1166 1221 1344 1345 1417 1472 1478 1480 1481 1484 1488 1491 1493\n",
      " 1494 1496 1504 1505 1510 1522 1523 1530]\n",
      "Dropped 98 epochs: 9, 10, 12, 24, 27, 28, 32, 33, 47, 49, 50, 61, 62, 66, 110, 130, 137, 138, 139, 163, 182, 191, 192, 235, 267, 268, 269, 270, 294, 295, 296, 310, 319, 320, 325, 327, 335, 336, 337, 408, 411, 497, 498, 519, 523, 525, 561, 562, 578, 600, 622, 623, 752, 753, 754, 760, 761, 814, 815, 905, 906, 926, 927, 968, 970, 1013, 1014, 1158, 1166, 1168, 1220, 1221, 1344, 1345, 1346, 1358, 1417, 1418, 1420, 1429, 1430, 1472, 1478, 1480, 1481, 1484, 1488, 1491, 1493, 1494, 1496, 1504, 1505, 1510, 1522, 1523, 1530, 1551\n"
     ]
    }
   ],
   "source": [
    "epochs_faster = prepare_epochs_for_ica(epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_faster.plot_drop_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run ICA\n",
    "\n",
    "\n",
    "When visualizing the components, it is recommended to subset the data (see below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_components': 32, 'method': 'picard', 'decim': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings[\"ica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings[\"ica\"]\n",
    "\n",
    "settings[\"ica\"][\"method\"] = 'picard'\n",
    "settings[\"ica\"][\"decim\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Loading data for 1501 events and 726 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weian/.conda/envs/eeg-workshop/lib/python3.7/site-packages/mne/utils/check.py:92: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LooseVersion(library.__version__) < LooseVersion(min_version):\n",
      "/Users/weian/.conda/envs/eeg-workshop/lib/python3.7/site-packages/mne/utils/check.py:92: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LooseVersion(library.__version__) < LooseVersion(min_version):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 32 components\n",
      "Loading data for 1501 events and 726 original time points ...\n",
      "Fitting ICA took 29.4s.\n",
      "EOG channels are not found. Attempting to use Fp1,Fp2 channels as EOG channels.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Loading data for 1501 events and 726 original time points ...\n",
      "Loading data for 1501 events and 726 original time points ...\n",
      "Loading data for 1501 events and 726 original time points ...\n",
      "Loading data for 1501 events and 726 original time points ...\n"
     ]
    }
   ],
   "source": [
    "ica = run_ica(epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot component topographies\n",
    "ica.plot_components()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize components on epochs\n",
    "# Subset epochs to reduce execution time (e.g. take epochs from every 7th event)\n",
    "subset = list(epochs.event_id.keys())[::7]\n",
    "# Exclude components by selecting them, right click on component name to visualize source:\n",
    "ica.plot_sources(epochs_faster[subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica.exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1501 events and 726 original time points ...\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (32 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 64 PCA components\n"
     ]
    }
   ],
   "source": [
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "epochs_ica = apply_ica(epochs_faster, ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 10 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, Pz, P3, ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " description: n_components: 1\n",
      " dig: 64 items (64 EEG)\n",
      " highpass: 0.5 Hz\n",
      " lowpass: 45.0 Hz\n",
      " meas_date: 2021-02-08 14:08:06 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      " temp: 61_E_Day1_ICA\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(epochs_ica.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualize ICA cleaned epochs (optional)\n",
    "\n",
    "This step can be repeated after each preprocessing step, or you can also do a final inspection at the end. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica[subset].plot(n_epochs=10, n_channels=32, scalings={'eeg': 20e-6},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save cleaned epochs (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.info[\"temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(epochs_path, f'{epochs_ica.info[\"temp\"]}-epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.save(os.path.join(epochs_path, f'{epochs_ica.info[\"temp\"]}-epo.fif.gz'),\n",
    "                overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create a log file \n",
    "\n",
    "We can create a log file for the preprocessed data and store metadata\n",
    "that could be useful to remember. You can add more columns to this, or \n",
    "remove the ones that are not needed. For documentation purporses, it is \n",
    "recommended to store the number of rejected and total epochs, the number of\n",
    "ICA components that were rejected, the number of interpolated electrodes etc.\n",
    "You can also add a column with \"notes\" to add custom descriptions about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = 'additional notes about the data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = os.path.join(os.path.join(epochs_path, 'log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.info[\"temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log(log_file_path, epochs_ica, notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = os.path.join(os.path.join(epochs_path, 'log.csv'))\n",
    "print(log_file_path)\n",
    "\n",
    "#update_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['autoreject']['threshold'] = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting autoreject on random (n=375) subset of epochs: \n",
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weian/.conda/envs/eeg-workshop/lib/python3.7/site-packages/mne/externals/tqdm/__init__.py:5: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(__version__) < LooseVersion('4.36'):\n",
      "/Users/weian/.conda/envs/eeg-workshop/lib/python3.7/site-packages/mne/externals/tqdm/__init__.py:5: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(__version__) < LooseVersion('4.36'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00391ef305ef4c768abfd9913ccc0998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/64 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b156829937432587b4e58bbe1be509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/64 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb7b6c2ae9a46098b5f4e6f5da0a9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/375 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3394875531db4249b7f6a61fd3fdccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | n_interp : 0/3 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903a9e779ee44d7a9f444f432f3a51a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/375 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0be283e92049aab2d31c369581788f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b7a5f8120444699437af1ed1aee0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/375 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d4fe0e2b6045069b778cc75e01eb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e86cafe613a44b7a9db0974aadaa7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/375 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dae743f4cd467fa49f8d7254991c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Estimated consensus=0.60 and n_interpolate=32\n",
      "\n",
      "AUTOREJECT report\n",
      "There are 60 bad epochs found with Autoreject. You can assess these epochs with reject_log.bad_epochs\n",
      "\n",
      "There are 205 bad epochs where more than 15% of the channels were noisy. You can assess these epochs with reject_log.report\n"
     ]
    }
   ],
   "source": [
    "reject_log = run_autoreject(epochs_ica, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can decide how strict should be the epoch rejection.\n",
    "# You can drop only those that were marked as bad epochs, or a more \n",
    "# strict rejection threshold can be if you drop epochs where more than\n",
    "# 15% of the channels were marked as noisy.\n",
    "\n",
    "# You can plot the epochs with Autoreject, where bad epochs are marked with\n",
    "# red colors. \n",
    "\n",
    "#reject_log.plot_epochs(epochs_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 205 epochs: 2, 3, 9, 22, 23, 28, 29, 32, 33, 35, 36, 38, 39, 40, 43, 50, 62, 70, 79, 82, 99, 102, 118, 119, 123, 161, 164, 170, 173, 177, 179, 188, 189, 193, 199, 203, 205, 206, 210, 222, 223, 231, 235, 241, 242, 243, 253, 261, 265, 266, 271, 272, 279, 285, 288, 291, 292, 293, 294, 295, 297, 302, 307, 311, 320, 322, 356, 361, 369, 377, 396, 417, 437, 450, 452, 453, 464, 465, 472, 476, 479, 482, 494, 495, 502, 517, 519, 529, 555, 564, 571, 580, 594, 595, 601, 602, 608, 610, 627, 630, 634, 659, 661, 665, 678, 681, 682, 683, 685, 686, 689, 699, 703, 704, 705, 708, 710, 713, 727, 728, 732, 737, 743, 756, 758, 759, 776, 796, 802, 806, 830, 834, 835, 848, 853, 863, 878, 879, 886, 896, 905, 906, 907, 960, 976, 984, 993, 1012, 1020, 1028, 1036, 1045, 1055, 1075, 1078, 1080, 1083, 1089, 1091, 1107, 1108, 1110, 1123, 1140, 1142, 1150, 1151, 1161, 1163, 1192, 1204, 1218, 1220, 1235, 1243, 1245, 1251, 1273, 1274, 1295, 1311, 1319, 1320, 1322, 1341, 1342, 1345, 1347, 1350, 1366, 1374, 1384, 1385, 1424, 1435, 1443, 1444, 1448, 1451, 1453, 1474, 1476, 1480, 1488, 1497\n"
     ]
    }
   ],
   "source": [
    "epochs_autoreject = apply_autoreject(epochs=epochs_ica, reject_log=reject_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61_E_Day1_ICA_autoreject'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_autoreject.info[\"temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(epochs_path, f'{epochs_autoreject.info[\"temp\"]}-epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_autoreject.save(os.path.join(epochs_path, f'{epochs_autoreject.info[\"temp\"]}-epo.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update log\n",
    "notes = ''\n",
    "\n",
    "update_log(log_file_path, epochs_autoreject, notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find and interpolate bad channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = get_noisy_channels(epochs=epochs_autoreject, with_ransac=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bads.extend(['T7', 'CPz'])\n",
    "\n",
    "# .append() for string e.g. 'F7'\n",
    "# .extend() for list ['F7', 'F8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac = interpolate_bad_channels(epochs=epochs_autoreject, bads=bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epochs_ransac.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many trials are left for each condition per epoch\n",
    "for i in range(5):\n",
    "    print(i+1, epochs[f\"epoch == {i+1}& triplet_type == 'HR'\"].average().nave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(i+1, epochs_ransac[f\"epoch == {i+1}& triplet_type == 'HR'\"].average().nave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect which sensors were interpolated (if any)\n",
    "print(epochs_ransac.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final visual inspection\n",
    "\n",
    "Mark epochs that should be dropped,  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use indexing to plot fewer epochs (faster) e.g. [::7] shows only every 7th epoch\n",
    "epochs_ransac[::7].plot(n_epochs=10,\n",
    "                       n_channels=32,\n",
    "                # group_by='position',\n",
    "                       scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Set average reference\n",
    "\n",
    "To set a “virtual reference” that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.set_eeg_reference('average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save cleaned epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(epochs_path, f'{epochs_ransac.info[\"temp\"]}-epo.fif.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ransac.save(os.path.join(epochs_path, f'{epochs_ransac.info[\"temp\"]}-epo.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log(log_file_path, epochs_ransac, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = ['F7', 'F5', 'F3', 'FC5', 'FC3',\n",
    "           'F1', 'Fz', 'F2', 'FC1', 'FCz', 'FC2',\n",
    "           'F4', 'F6', 'F8', 'FC4', 'FC6',\n",
    "           'FT7', 'T7', 'TP7', \n",
    "           'C3', 'Cz', 'C4',\n",
    "           'FT8', 'T8', 'TP8',\n",
    "           'CP5', 'CP3', 'P7', 'P5', 'P3',\n",
    "           'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2',\n",
    "           'CP4', 'CP6', 'P4', 'P6', 'P8',\n",
    "           'PO3', 'PO7', 'O1',\n",
    "           'PO4', 'PO8', 'O2',]\n",
    "\n",
    "\n",
    "epochs_evoked = epochs_ransac.copy().pick_channels(ch_names, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_evoked.plot_psd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_H = epochs_evoked[\"epoch == 1 & triplet == 'H'\"].average()\n",
    "e1_H.apply_baseline((-0.2, 0.0))\n",
    "#e1_H.comment = f\"{epochs_evoked.comment}_e1_H\"\n",
    "\n",
    "e1_H.plot('F8', spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
