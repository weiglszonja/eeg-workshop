{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing pipeline tutorial\n",
    "\n",
    "## Outline\n",
    "\n",
    "<img src=\"static/preprocessing_pipeline_diagram.svg\">\n",
    "\n",
    "1. __Temporal filtering__\n",
    "\n",
    "High-frequency artefacts and slow drifts are removed with a zero-phase bandpass filter \n",
    "using mne-Python [1]. \n",
    "\n",
    "2. __Segmenting the data__\n",
    "\n",
    "Epochs are non-overlapping data segments created from the continuous data with a \n",
    "given duration.\n",
    "Epochs can be created from (1) events; there is a custom method that created epochs \n",
    "based on annotations in the raw data, (2) without events, data segments are created \n",
    "from the beginning of the raw data. \n",
    "\n",
    "3. __Outlier data rejection__  \n",
    "\n",
    "- _Preliminar rejection_\n",
    "\n",
    "Epochs are rejected based on a global threshold on the z-score (> 3) of the epoch \n",
    "variance and amplitude range.\n",
    "\n",
    "- _ICA decomposition_  \n",
    "\n",
    "The default method is the infomax algorithm, however it can be changed in the \n",
    "configuration file along with the number of components and the decimation parameter. \n",
    "Components containing blink artefacts are automatically marked with mne-Python.\n",
    "The ICA sourced can be visualized and interactively selected and rejected based on \n",
    "their topographies, time-courses or frequency spectra.\n",
    "\n",
    "- _Autoreject_  \n",
    "\n",
    "Autoreject [2, 3] uses unsupervised learning to estimate the rejection threshold for \n",
    "the epochs. In order to reduce computation time that increases with the number of \n",
    "segments and channels, autoreject can be fitted on a representative subset of epochs \n",
    "(25% of total epochs). Once the parameters are learned, the solution can be applied to \n",
    "any data that contains channels that were used during fit.\n",
    "\n",
    "4. __Outlier channel interpolation__\n",
    "\n",
    "The Random Sample Consensus (RANSAC) algorithm [4] selects a random subsample of good \n",
    "channels to make predictions of each channel in small non-overlapping 4 seconds long \n",
    "time windows. It uses a method of spherical splines (Perrin et al., 1989) to \n",
    "interpolate the bad sensors.\n",
    "\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower);    \n",
    "\n",
    "switch to ```%matplotlib inline``` for faster but static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import pandas as pd\n",
    "from meeg_tools.preprocessing import *\n",
    "from meeg_tools.utils.epochs import create_epochs_from_events, create_metadata\n",
    "from meeg_tools.utils.raw import read_raw_measurement, filter_raw\n",
    "from meeg_tools.utils.log import update_log\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "\n",
    "\n",
    "See [this](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html) documentation for help with supported file formats.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a970ba367545169e365876186fa5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data', filename=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "base_path = 'data/'\n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected file\n",
    "read_raw_measurement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, Pz, P3, ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 64 items (64 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: 2021-02-08 14:08:06 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      " temp: 61_E_Day1\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select condition\n",
    "\n",
    "The current logic for saving the preprocessed files is to create subfolders inside `base_path`,\n",
    "with the name \"preprocessed\" and the name of the condition (e.g. \"epochs_asrt\", \"epochs_rs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocessed/epochs_asrt\n"
     ]
    }
   ],
   "source": [
    "condition = 'epochs_asrt'\n",
    "\n",
    "\n",
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "epochs_path = os.path.join(base_path, folder_name, condition)\n",
    "\n",
    "\n",
    "# Create path to epoch files\n",
    "if not os.path.exists(epochs_path):\n",
    "    os.makedirs(epochs_path)\n",
    "    \n",
    "print(epochs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal filtering\n",
    "\n",
    "We apply a bandpass filter on the continuous data using the `filter_raw` function.\n",
    "\n",
    "The default parameters can be checked with `settings['bandpass_filter']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'low_freq': 0.5, 'high_freq': 45}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['bandpass_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_raw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epochs\n",
    "\n",
    "### Create epochs for event-related analysis\n",
    "\n",
    "We create epochs from __selected__ events (stimuli) in the data.\n",
    "\n",
    "Epochs are created with respect to the stimulus onset defined by `start_time` and \n",
    "`end_time` within `settings['epochs']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': 0.0, 'end_time': 1.0, 'duration': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['epochs']['start_time'] = -0.250\n",
    "settings['epochs']['end_time'] = 0.750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_ids = np.concatenate([np.arange(10, 53, 1), \n",
    "                             np.arange(10, 53, 1) + 100,\n",
    "                            [211, 212, 213, 214, 215, 216]]) # boundaries of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_epochs_from_events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata for epochs (optional)\n",
    "\n",
    "- adding metadata makes it easier to select epochs of different types\n",
    "- custom triggers are selected from the raw instance\n",
    "\n",
    "- metadata can be added or replaced later (e.g. after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metadata?\n",
    "\n",
    "# We have to assign it to the epochs instance to take effect\n",
    "#epochs.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselecting epochs \n",
    "# Here we could also include thrills, repetitions, or practice stimuli.\n",
    "# ICA should not run on duplicate data (epochs should not be overlapping!)\n",
    "\n",
    "# epochs = epochs[\"triplet == 'L' | triplet == 'H'\"]\n",
    "# epochs = epochs[\"answer == 'correct'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs.metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run preprocessing\n",
    "\n",
    "\n",
    "### 1.1. Preliminary epoch rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_epochs_for_ica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Run ICA\n",
    "\n",
    "\n",
    "When visualizing the components, it is recommended to subset the data (see below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_components': 32, 'method': 'picard', 'decim': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings[\"ica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot component topographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize components on epochs\n",
    "# Subset epochs to reduce execution time (e.g. take epochs from every 7th event)\n",
    "#subset = list(epochs.event_id.keys())[::7]\n",
    "# Exclude components by selecting them, right click on component name to visualize source:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After selecting the components to exclude, apply ICA to epochs\n",
    "apply_ica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Visualize ICA cleaned epochs (optional)\n",
    "\n",
    "This step can be repeated after each preprocessing step, or you can also do a final inspection at the end. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Save cleaned epochs (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs_ica.info['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs_ica.save(os.path.join(target_path, f'{epochs_ica.info[\"temp\"]}-epo.fif.gz'),overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create a log file \n",
    "\n",
    "We can create a log file for the preprocessed data and store metadata\n",
    "that could be useful to remember. You can add more columns to this, or \n",
    "remove the ones that are not needed. For documentation purporses, it is \n",
    "recommended to store the number of rejected and total epochs, the number of\n",
    "ICA components that were rejected, the number of interpolated electrodes etc.\n",
    "You can also add a column with \"notes\" to add custom descriptions about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocessed/epochs_asrt/log.csv\n"
     ]
    }
   ],
   "source": [
    "log_file_path = os.path.join(os.path.join(epochs_path, 'log.csv'))\n",
    "print(log_file_path)\n",
    "update_log?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_autoreject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can decide how strict should be the epoch rejection.\n",
    "# You can drop only those that were marked as bad epochs, or a more \n",
    "# strict rejection threshold can be if you drop epochs where more than\n",
    "# 15% of the channels were marked as noisy.\n",
    "\n",
    "# You can plot the epochs with Autoreject, where bad epochs are marked with\n",
    "# red colors. \n",
    "\n",
    "#reject_log.plot_epochs(epochs_faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_autoreject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs_autoreject.save(os.path.join(epochs_path, f'{epochs_autoreject.info[\"temp\"]}-epo.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update log\n",
    "#notes = ''\n",
    "#update_log(log_file_path, epochs_autoreject, notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find and interpolate bad channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_noisy_channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_bad_channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_components: 1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_ransac.info['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many trials are left for each condition per epoch\n",
    "# for i in range(5):\n",
    "#     print(i+1, epochs_ransac[f\"epoch == {i+1}& triplet == 'L'\"].average().nave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect which sensors were interpolated (if any)\n",
    "print(epochs_ransac.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final visual inspection\n",
    "\n",
    "Mark epochs that should be dropped,  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use indexing to plot fewer epochs (faster) e.g. [::7] shows only every 7th epoch\n",
    "# epochs_ransac[::7].plot(n_epochs=10,\n",
    "#                        n_channels=32,\n",
    "#                 # group_by='position',\n",
    "#                        scalings={'eeg': 20e-6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Set average reference\n",
    "\n",
    "To set a “virtual reference” that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save cleaned epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs_ransac.save(os.path.join(epochs_path, f'{epochs_ransac.info[\"temp\"]}-epo.fif.gz'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_log(log_file_path, epochs_ransac, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
