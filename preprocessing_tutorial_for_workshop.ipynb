{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing pipeline tutorial\n",
    "\n",
    "## Outline\n",
    "\n",
    "<img src=\"static/preprocessing_pipeline_diagram.svg\">\n",
    "\n",
    "1. __Temporal filtering__\n",
    "\n",
    "High-frequency artefacts and slow drifts are removed with a zero-phase bandpass filter \n",
    "using mne-Python [1]. \n",
    "\n",
    "2. __Segmenting the data__\n",
    "\n",
    "Epochs are non-overlapping data segments created from the continuous data with a \n",
    "given duration.\n",
    "Epochs can be created from (1) events; there is a custom method that created epochs \n",
    "based on annotations in the raw data, (2) without events, data segments are created \n",
    "from the beginning of the raw data. \n",
    "\n",
    "3. __Outlier data rejection__  \n",
    "\n",
    "- _Preliminar rejection_\n",
    "\n",
    "Epochs are rejected based on a global threshold on the z-score (> 3) of the epoch \n",
    "variance and amplitude range.\n",
    "\n",
    "- _ICA decomposition_  \n",
    "\n",
    "The default method is the infomax algorithm, however it can be changed in the \n",
    "configuration file along with the number of components and the decimation parameter. \n",
    "Components containing blink artefacts are automatically marked with mne-Python.\n",
    "The ICA sourced can be visualized and interactively selected and rejected based on \n",
    "their topographies, time-courses or frequency spectra.\n",
    "\n",
    "- _Autoreject_  \n",
    "\n",
    "Autoreject [2, 3] uses unsupervised learning to estimate the rejection threshold for \n",
    "the epochs. In order to reduce computation time that increases with the number of \n",
    "segments and channels, autoreject can be fitted on a representative subset of epochs \n",
    "(25% of total epochs). Once the parameters are learned, the solution can be applied to \n",
    "any data that contains channels that were used during fit.\n",
    "\n",
    "4. __Outlier channel interpolation__\n",
    "\n",
    "The Random Sample Consensus (RANSAC) algorithm [4] selects a random subsample of good \n",
    "channels to make predictions of each channel in small non-overlapping 4 seconds long \n",
    "time windows. It uses a method of spherical splines (Perrin et al., 1989) to \n",
    "interpolate the bad sensors.\n",
    "\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013, ISSN 1662-453X\n",
    "\n",
    "[2] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, “Automated rejection and repair of bad trials in MEG/EEG.” In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n",
    "\n",
    "[3] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. “Autoreject: Automated artifact rejection for MEG and EEG data”. NeuroImage, 159, 417-429.\n",
    "\n",
    "[4] Bigdely-Shamlo, N., Mullen, T., Kothe, C., Su, K. M., & Robbins, K. A. (2015). The PREP pipeline: standardized preprocessing for large-scale EEG analysis. Frontiers in neuroinformatics, 9, 16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "\n",
    "```%matplotlib qt``` is the recommended backend for interactive visualization (can be slower);    \n",
    "\n",
    "switch to ```%matplotlib inline``` for faster but static plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import pandas as pd\n",
    "from meeg_tools.preprocessing import *\n",
    "from meeg_tools.utils.epochs import create_epochs_from_events\n",
    "from meeg_tools.utils.raw import read_raw_measurement, filter_raw\n",
    "from meeg_tools.utils.log import update_log\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data\n",
    "\n",
    "\n",
    "See [this](https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html) documentation for help with supported file formats.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7814dfce65fd483096cb74b96a40bd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/Users/weian/Library/Mobile Documents/com~apple~CloudDocs/crnl/eeg-workshop/data', filename=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the widget to navigate to the experiment folder path and select an EEG file \n",
    "base_path = 'data/'\n",
    "fc = FileChooser(base_path)\n",
    "fc.filter_pattern = ['*.vhdr', '*.edf']\n",
    "\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected file\n",
    "read_raw_measurement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select condition\n",
    "\n",
    "The current logic for saving the preprocessed files is to create subfolders inside `base_path`,\n",
    "with the name \"preprocessed\" and the name of the condition (e.g. \"epochs_asrt\", \"epochs_rs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocessed/epochs_asrt\n"
     ]
    }
   ],
   "source": [
    "condition = 'epochs_asrt'\n",
    "\n",
    "\n",
    "# Create folder for preprocessed and interim files\n",
    "folder_name = 'preprocessed'\n",
    "epochs_path = os.path.join(base_path, folder_name, condition)\n",
    "\n",
    "\n",
    "# Create path to epoch files\n",
    "if not os.path.exists(epochs_path):\n",
    "    os.makedirs(epochs_path)\n",
    "    \n",
    "print(epochs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal filtering\n",
    "\n",
    "We apply a bandpass filter on the continuous data using the `filter_raw` function.\n",
    "\n",
    "The default parameters can be checked with `settings['bandpass_filter']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'low_freq': 0.5, 'high_freq': 45}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['bandpass_filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_raw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epochs\n",
    "\n",
    "### Create epochs for event-related analysis\n",
    "\n",
    "We create epochs from __selected__ events (stimuli) in the data.\n",
    "\n",
    "Epochs are created with respect to the stimulus onset defined by `start_time` and \n",
    "`end_time` within `settings['epochs']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': 0.0, 'end_time': 1.0, 'duration': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['epochs']['start_time'] = -0.250\n",
    "settings['epochs']['end_time'] = 0.750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import events_from_annotations\n",
    "events, _ = events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_ids = np.concatenate([np.arange(10, 53, 1), \n",
    "                             np.arange(10, 53, 1) + 100,\n",
    "                            [211, 212, 213, 214, 215, 216]]) # boundaries of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_epochs_from_events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create metadata for epochs (optional)\n",
    "\n",
    "- adding metadata makes it easier to select epochs of different types\n",
    "- custom triggers are selected from the raw instance\n",
    "\n",
    "- metadata can be added or replaced later (e.g. after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `create_metadata` not found.\n"
     ]
    }
   ],
   "source": [
    "create_metadata?\n",
    "\n",
    "# We have to assign it to the epochs instance to take effect\n",
    "# epochs.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselecting epochs \n",
    "# Here we could also include thrills, repetitions, or practice stimuli.\n",
    "# ICA should not run on duplicate data (epochs should not be overlapping!)\n",
    "\n",
    "# epochs = epochs[\"triplet == 'L' | triplet == 'H'\"]\n",
    "# epochs = epochs[\"answer == 'correct'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
